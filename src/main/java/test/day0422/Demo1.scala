package test.day0422

import breeze.linalg.functions.cosineDistance
import breeze.linalg.{DenseVector, norm}
import org.apache.log4j.{Level, Logger}
import org.apache.spark.SparkConf
import org.apache.spark.mllib.evaluation.RegressionMetrics
import org.apache.spark.mllib.recommendation.{ALS, MatrixFactorizationModel, Rating}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.{DataFrame, Row, SparkSession}

/**
 * ååŒè¿‡æ»¤

    1.	æ ¹æ®u.dataæ•°æ®é›†ï¼Œå°†æ•°æ®é›†ä»¥7ï¼š3çš„æ¯”ä¾‹åˆ†ä¸ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
    ä½¿ç”¨æœ€å°äº¤æ›¿äºŒä¹˜æ³•å®Œæˆæ¨¡å‹è®­ç»ƒï¼Œå› å­ä¸º100ï¼Œå…¶ä»–å‚æ•°ä»»æ„
    ï¼ˆaï¼‰è¾“å‡ºç”¨æˆ·å’Œå•†å“å› å­æ•°é‡
    ï¼ˆbï¼‰é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦æ‰¾åˆ°ä¸ç”µå½±idä¸º617ç›¸ä¼¼åº¦æœ€é«˜çš„10éƒ¨ç”µå½±ï¼Œå¹¶ç»“åˆç”µå½±æ•°æ®		é›†ï¼ˆu.itemï¼‰è¾“å‡ºè¯¥ç»“æœ10éƒ¨ç”µå½±çš„ä¿¡æ¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•è‡ªå®šä¹‰ï¼‰
    ï¼ˆcï¼‰ä¸ºç”¨æˆ·303æ¨è10éƒ¨ç”µå½±
    ï¼ˆdï¼‰å°†è®­ç»ƒçš„æ¨¡å‹é¢„æµ‹æ•°æ®ä¸æºæ•°æ®åšç¬›å¡å°”ç§¯ï¼Œæ±‚æ ¹æ–¹å·®å’Œå‡æ–¹å·®è¯¯æ ¹ï¼Œå‡æ–¹å·®å’Œå‡æ–¹å·®è¯¯æ ¹<1.5ä¸ºæ¨¡å‹å‡†ç¡®åº¦ï¼ˆå‡æ–¹å·®å’Œå‡æ–¹å·®è¯¯æ ¹æ–¹æ³•è‡ªå®šä¹‰ï¼‰
    ï¼ˆeï¼‰æ ¹æ®è®­ç»ƒæ¨¡å‹è¾“å‡ºæµ‹è¯•æ•°æ®é›†é¢„æµ‹ç»“æœ
    ï¼ˆfï¼‰æ ¹æ®mllibçš„å†…ç½®å‡½æ•°æ±‚å‡æ–¹å·®å’Œå‡æ–¹å·®è¯¯æ ¹
 */
object Demo1 {
  def main(args: Array[String]): Unit = {
    //æ ¹æ®u.dataæ•°æ®é›†ï¼Œå°†æ•°æ®é›†ä»¥7ï¼š3çš„æ¯”ä¾‹åˆ†ä¸ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
    Logger.getLogger("org").setLevel(Level.OFF)
    val session: SparkSession = SparkSession.builder().config(new SparkConf().setMaster("local[*]").setAppName("asd")).getOrCreate()
    val context = session.sparkContext

    val value: RDD[Rating] = context.textFile("/home/rjxy/IdeaProjects/spark/spark_mllib_course/src/main/resources/ml-100k/u.data")
      .map(
        item => {
          val strings: Array[String] = item.split("\t")
          // userid (ç”¨æˆ·ğŸ†”id) ã€item id (é¡¹ç›®id) ã€ rating(è¯„åˆ†)ã€timestamp(æ—¥æœŸæ—¶é—´)
          Rating(strings(0).toInt, strings(1).toInt, strings(2).toInt)
        }
      )

    val array: Array[RDD[Rating]] = value.randomSplit(Array(0.7, 0.3), 1l)


//    array.foreach((item: RDD[Rating]) => item.foreach(println))

    val v1: RDD[Rating] = array(0)
    val v2: RDD[Rating] = array(1)


    /**
     *    è®­ç»ƒä¸€ä¸ªçŸ©é˜µåˆ†è§£æ¨¡å‹ï¼Œç»™å®šç”¨æˆ·å¯¹äº§å“å­é›†çš„è¯„çº§RDDã€‚
     * è¯„çº§çŸ©é˜µè¿‘ä¼¼ä¸ºç»™å®šç§©çš„ä¸¤ä¸ªä½ç§©çŸ©é˜µ(ç‰¹å¾æ•°)çš„ä¹˜ç§¯ã€‚
     * ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒALSä¼šæ ¹æ®â€œè¯„çº§â€ä¸­çš„åˆ†åŒºæ•°é‡ï¼Œä»¥ä¸€å®šçš„å¹¶è¡Œåº¦è¿­ä»£è¿è¡Œã€‚
     *
        numBlocks æ˜¯ç”¨äºå¹¶è¡ŒåŒ–è®¡ç®—çš„åˆ†å—ä¸ªæ•° (è®¾ç½®ä¸º-1ï¼Œä¸ºè‡ªåŠ¨é…ç½®)ã€‚
        rank æ˜¯æ¨¡å‹ä¸­éšè¯­ä¹‰å› å­çš„ä¸ªæ•°ã€‚
        iterations æ˜¯è¿­ä»£çš„æ¬¡æ•°ã€‚
        lambda æ˜¯ALSçš„æ­£åˆ™åŒ–å‚æ•°ã€‚
        implicitPrefs å†³å®šäº†æ˜¯ç”¨æ˜¾æ€§åé¦ˆALSçš„ç‰ˆæœ¬è¿˜æ˜¯ç”¨é€‚ç”¨éšæ€§åé¦ˆæ•°æ®é›†çš„ç‰ˆæœ¬ã€‚
        alpha æ˜¯ä¸€ä¸ªé’ˆå¯¹äºéšæ€§åé¦ˆ ALS ç‰ˆæœ¬çš„å‚æ•°ï¼Œè¿™ä¸ªå‚æ•°å†³å®šäº†åå¥½è¡Œä¸ºå¼ºåº¦çš„åŸºå‡†ã€‚
     */

    //ä½¿ç”¨æœ€å°äº¤æ›¿äºŒä¹˜æ³•å®Œæˆæ¨¡å‹è®­ç»ƒï¼Œå› å­ä¸º100ï¼Œå…¶ä»–å‚æ•°ä»»æ„  çŸ©é˜µåˆ†è§£æ¨¡å‹
    val model: MatrixFactorizationModel = ALS.train(v1, 100, 10, 0.01)

    //å¯ä»¥è°ƒæ•´è¿™äº›å‚æ•°ï¼Œä¸æ–­ä¼˜åŒ–ç»“æœï¼Œä½¿å‡æ–¹å·®å˜å°ã€‚æ¯”å¦‚ï¼š  iterationsè¶Šå¤šï¼Œ  lambdaè¾ƒå°ï¼Œ  å‡æ–¹å·®ä¼šè¾ƒå°ï¼Œ  æ¨èç»“æœè¾ƒä¼˜ã€‚
    // ä¸Šé¢çš„ä¾‹å­ä¸­è°ƒç”¨äº† ALS.train(ratings, rank, numIterations, 0.01) ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¾ç½®å…¶ä»–å‚æ•°ï¼Œè°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š

    println("è®­ç»ƒæ¨¡å‹ç”¨æˆ·å› å­æ•°é‡  "+model.productFeatures.count())
    println("å•†å“å› å­æ•°é‡  "+model.userFeatures.count())

    //æµ‹è¯•åŸæ•°æ®
    val testRating: RDD[((Int, Int), Double)] = v1.map(
      (item: Rating) => {
        ((item.user, item.product), item.rating)
      }
    )
    //æµ‹è¯•å»æ‰è¯„åˆ†çš„æ•°æ®
    val test: RDD[(Int, Int)] = v1.map(
      (item: Rating) =>{
        (item.user,item.product)
      }
    )

    //ç¬¬ä¸€æ¡ç»“æœè®°å½•((3,1),(1.0,-0.22756397347958202))ä¸­ï¼Œ(3,1)åˆ†åˆ«è¡¨ç¤º3å·ç”¨æˆ·å’Œ1å·å•†å“ï¼Œè€Œ1.0æ˜¯å®é™…çš„ä¼°è®¡åˆ†å€¼ï¼Œ-0.22756397347958202æ˜¯ç»è¿‡æ¨èçš„é¢„æµ‹åˆ†å€¼ã€‚
    val ratingsAndPredictions: RDD[((Int, Int), (Double, Double))] = model.predict(test).map((item: Rating) =>
      ((item.user, item.product), item.rating)
    ).join(testRating)

    println(" (user,product) é¢„æµ‹ç»“æœ ä¸ çœŸå®ç»“æœ 10ä¸ª ")
    ratingsAndPredictions.take(10).foreach(println)

    val value1: RDD[Double] =  ratingsAndPredictions.map {
      case ((user, pro), (r1, r2)) =>
        //è®¡ç®—æ–¹å·®
        val err: Double = r1 - r2
        err * err
    }
//    println("å‡æ–¹å·®   "+ value1.mean())
    println("è‡ªå®šä¹‰å‡æ–¹è¯¯å·®  (Mean squared error) (MSE) "+ BigDecimal.valueOf(value1.sum()/value1.count()))
    println("è‡ªå®šä¹‰å‡æ–¹æ ¹è¯¯å·® (Root Mean squared error) (RMSE)   "+ BigDecimal.valueOf(math.sqrt(value1.sum()/value1.count())))

    //æ ·æœ¬å‡å€¼
    val testMean: Double = testRating.map(_._2).mean()
    //æ ·æœ¬å‡æ–¹å·®
    val testSD: Double = testRating.map(
      (item: ((Int, Int), Double)) => {
        math.pow(item._2 - testMean, 2)
      }
    ).mean()

    //å¼€æ ¹
    println("è‡ªå®šä¹‰å‡æ–¹å·® (Standard Deviation)   "+ BigDecimal.valueOf(math.sqrt(testSD)))

    //é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦æ‰¾åˆ°ä¸ç”µå½±idä¸º617ç›¸ä¼¼åº¦æœ€é«˜çš„10éƒ¨ç”µå½±ï¼Œå¹¶ç»“åˆç”µå½±æ•°æ®é›†ï¼ˆu.itemï¼‰è¾“å‡ºè¯¥ç»“æœ10éƒ¨ç”µå½±çš„ä¿¡æ¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•è‡ªå®šä¹‰ï¼‰
    //ä½™å¼¦ç›¸ä¼¼åº¦

    val productFeatures: RDD[(Int, Array[Double])] = model.productFeatures

    val moviehead: Array[Double] = productFeatures.lookup(617).head

    val movie617: DenseVector[Double] = DenseVector(moviehead)

    val value2: RDD[(Int, Double)] = productFeatures.map(
      (item: (Int, Array[Double])) => {
        // cosineDistance(a,b) = (a dot b)/(norm(a) * norm(b))
        val itemVector: DenseVector[Double] = DenseVector(item._2)

        (item._1, itemVector.dot(movie617) / (norm(itemVector) * norm(movie617)))
      }
    )
//    guangwang
    /**
     * implicit
     *    //
     *    dot: OpMulInner.Impl2[T, U, Double],
     *    //
          normT: norm.Impl[T, Double],
          //
          normU: norm.Impl[U, Double]
     */
//    cosineDistance
//      .cosineDistanceFromDotProductAndNorm[RDD[(Int, Array[Double])], DenseVector[Double]](
//        dot = OpMulInner(productFeatures,movie617),
//        normT = norm(productFeatures),
//        normU = norm(movie617))

    //cosineDistance  ä½™å¼¦è·ç¦»  ä½™å¼¦ç›¸ä¼¼åº¦  CosineSimilarity

    val value3: RDD[(Int, Double)] = productFeatures.map(
      i => {
        (i._1,cosineDistance(DenseVector(i._2), movie617))
      }
    )
    //æ‰€æœ‰ç”µå½±(id : name)
    val movie: collection.Map[String, String] = context.textFile("/home/rjxy/IdeaProjects/spark/spark_mllib_course/src/main/resources/ml-100k/u.item")
      .map(_.split("\\|")).map(item => (item(0),item(1))).collectAsMap()

    println("ï¼ˆbï¼‰é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦æ‰¾åˆ°ä¸ç”µå½±idä¸º617ç›¸ä¼¼åº¦æœ€é«˜çš„10éƒ¨ç”µå½±ï¼Œå¹¶ç»“åˆç”µå½±æ•°æ®é›†ï¼ˆu.itemï¼‰è¾“å‡ºè¯¥ç»“æœ10éƒ¨ç”µå½±çš„ä¿¡æ¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•è‡ªå®šä¹‰ï¼‰")
    value2.sortBy(-_._2).take(11).tail.foreach(
      (item: (Int, Double)) => println(item._1+"   "+ item._2+ "      "+movie(item._1.toString))
    )
    println("ï¼ˆ2222222222222222 è¿‡ä½™å¼¦ç›¸ä¼¼åº¦æ‰¾åˆ°ä¸ç”µå½±idä¸º617ç›¸ä¼¼åº¦æœ€é«˜çš„10éƒ¨ç”µå½±ï¼Œå¹¶ç»“åˆç”µå½±æ•°æ®é›†ï¼ˆu.itemï¼‰è¾“å‡ºè¯¥ç»“æœ10éƒ¨ç”µå½±çš„ä¿¡æ¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•è‡ªå®šä¹‰ï¼‰")
    value3.sortBy(-_._2).take(11).tail.foreach(
      (item: (Int, Double)) => println(item._1+"   "+ item._2+ "      "+movie(item._1.toString))
    )


    //ï¼ˆcï¼‰ä¸ºç”¨æˆ·303æ¨è10éƒ¨ç”µå½±
    println("ä¸ºç”¨æˆ·303æ¨è10éƒ¨ç”µå½±")

    model.recommendProducts(303,10).foreach(
      (item: Rating) => {
        println(item+"  ç”µå½±åå­—"+ movie(item.product.toString))
      }
    )


    /**
        ä¸ºç”¨æˆ·303æ¨è10éƒ¨ç”µå½±
        Rating(303,197,5.555111063968932)  ç”µå½±åå­—Graduate, The (1967)
        Rating(303,272,5.271673086383508)  ç”µå½±åå­—Good Will Hunting (1997)
        Rating(303,523,5.174819241439634)  ç”µå½±åå­—Cool Hand Luke (1967)
        Rating(303,212,5.163752858040008)  ç”µå½±åå­—Unbearable Lightness of Being, The (1988)
        Rating(303,59,5.09228998893902)  ç”µå½±åå­—Three Colors: Red (1994)
        Rating(303,23,5.05293043296605)  ç”µå½±åå­—Taxi Driver (1976)
        Rating(303,246,5.0341458527101794)  ç”µå½±åå­—Chasing Amy (1997)
        Rating(303,318,5.031931490739359)  ç”µå½±åå­—Schindler's List (1993)
        Rating(303,47,5.027232925900102)  ç”µå½±åå­—Ed Wood (1994)
        Rating(303,479,5.019819060187922)  ç”µå½±åå­—Vertigo (1958)
     */


    //è¾“å‡ºæµ‹è¯•æ•°æ®é›†é¢„æµ‹ç»“æœ
    println("è¾“å‡ºæµ‹è¯•æ•°æ®é›†é¢„æµ‹ç»“æœ")
    val testPredictRes: RDD[Rating] = model.predict(v2.map(item => {
      (item.user, item.product)
    }))

    testPredictRes.take(10).foreach(println)
    println("è¾“å‡ºæµ‹è¯•æ•°æ®é›†é¢„æµ‹ç»“æœç»“æŸ")
    import session.implicits._
    val frame: DataFrame = testPredictRes.toDF().as("a").join(v2.toDF().as("b"),Seq("user","product") )//col("a.user") === col("b.user") && col("a.product") === col("b.product")

    val testDataSetPredictionResults: RegressionMetrics = new RegressionMetrics(
      frame.rdd.map {
        case Row(user, product, rating, rating2) => (rating.toString.toDouble, rating2.toString.toDouble)
      }
    )

    println("testDataSetPredictionResults  ")
    println("testDataSetPredictionResults  æ ¹æ®mllibçš„å†…ç½®å‡½æ•°æ±‚  å‡æ–¹è¯¯å·®(MSE) å’Œ å‡æ–¹æ ¹è¯¯å·®(RMSE) å’Œ")
    println("testDataSetPredictionResults  å‡æ–¹è¯¯å·®   "+BigDecimal.valueOf(testDataSetPredictionResults.meanSquaredError))//å‡æ–¹è¯¯å·®
    println("testDataSetPredictionResults  å¹³å‡ç»å¯¹è¯¯å·®   "+BigDecimal.valueOf(testDataSetPredictionResults.meanAbsoluteError))//å¹³å‡ç»å¯¹è¯¯å·®
    println("testDataSetPredictionResults  æ–¹å·®   "+BigDecimal.valueOf(testDataSetPredictionResults.explainedVariance))//æ–¹å·®
    println("testDataSetPredictionResults  å‡æ–¹æ ¹è¯¯å·®   "+BigDecimal.valueOf(testDataSetPredictionResults.rootMeanSquaredError))//å‡æ–¹æ ¹è¯¯å·®



//    cosineDistance.cosineDistanceFromDotProductAndNorm


      //æ ¹æ®mllibçš„å†…ç½®å‡½æ•°æ±‚ å‡æ–¹è¯¯å·®(MSE) å’Œ å‡æ–¹æ ¹è¯¯å·®(RMSE) å’Œ å‡æ–¹å·®(Standard Deviation)

    //å›å½’æŒ‡æ ‡
    val regressionMetrics = new RegressionMetrics(
      ratingsAndPredictions
        .map {
          case ((user, product), (predicted, actual)) => (predicted, actual)
        }
    )
    println("æ ¹æ®mllibçš„å†…ç½®å‡½æ•°æ±‚  å‡æ–¹è¯¯å·®(MSE) å’Œ å‡æ–¹æ ¹è¯¯å·®(RMSE) å’Œ")
    println("å‡æ–¹è¯¯å·®   "+BigDecimal.valueOf(regressionMetrics.meanSquaredError))//å‡æ–¹è¯¯å·®
    println("å¹³å‡ç»å¯¹è¯¯å·®   "+BigDecimal.valueOf(regressionMetrics.meanAbsoluteError))//å¹³å‡ç»å¯¹è¯¯å·®
    println("æ–¹å·®   "+BigDecimal.valueOf(regressionMetrics.explainedVariance))//æ–¹å·®
    println("å‡æ–¹æ ¹è¯¯å·®   "+BigDecimal.valueOf(regressionMetrics.rootMeanSquaredError))//å‡æ–¹æ ¹è¯¯å·®


    val regressionMetrics2 = new RegressionMetrics(
      v1.map(
        (item) => {
          (item.rating,item.rating )
        }
      )
    )

    println("æ ¹æ®mllibçš„å†…ç½®å‡½æ•°æ±‚   å‡æ–¹å·®(Standard Deviation)")
    println("æ–¹å·®   "+BigDecimal.valueOf(regressionMetrics2.explainedVariance))//æ–¹å·®
    println("æ–¹å·®å¼€æ ¹ = å‡æ–¹å·®(Standard Deviation)"+BigDecimal.valueOf(math.sqrt(regressionMetrics2.explainedVariance)))//æ–¹å·®

//            1.1258227931225748
//    æ–¹å·®å¼€æ ¹ 1.1258227931225138
    context.stop()


  }
}
